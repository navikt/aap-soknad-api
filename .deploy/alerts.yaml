apiVersion: "nais.io/v1"
kind: "Alert"
metadata:
  name: aap-soknad-api-alerts
  labels:
    team: aap
    app: aap-soknad-api
  namespace: aap
spec:
  receivers:
    slack:
      channel: '#aap-github'
  alerts:
    - alert: aap-soknad-api-app-nede
      expr: kube_deployment_status_replicas_unavailable{deployment="aap-soknad-api",job="kubernetes-service-endpoints"} > 0
      for: 5m
      description: '\{{ $labels.app }} har utilgjengelige podder i \{{ $labels.kubernetes_namespace }}'
      action: 'kubectl describe pod -l app=\{{ $labels.deployment }} -n \{{ $labels.namespace }}` for events og `kubectl get pods -l app=\{{ $labels.deployment }} -n \{{ $labels.namespace }}` for å se feilende podder'
      sla: respond within 1h, during office hours
      severity: danger
    - alert: aap-soknad-api-kontinuerlig-restart
      expr: sum(increase(kube_pod_container_status_restarts_total{container=~"aap-soknad-api"}[5m])) by (container) > 2
      for: 2m
      description: '\{{ $labels.container }} har restartet flere ganger de siste 5 minuttene!'
      action: 'Se `kubectl describe pod \{{ $labels.container }}` for events, og `kubectl logs \{{ $labels.container }}` for logger'
      sla: respond within 1h, during office hours
      severity: danger
    - alert: aap-soknad-api-mangler-metrikker
      expr: absent(up{app=~"aap-soknad-api",job="kubernetes-pods"})
      for: 2m
      description: '\{{ $labels.app }} rapporterer ingen metrikker i \{{ $labels.kubernetes_namespace }}'
      action: 'Sjekk om \{{ $labels.app }} i \{{ $labels.kubernetes_namespace }} er oppe'
      sla: respond within 1h, during office hours
      severity: danger
    - alert: høy feilrate i logger
      expr: (100 * sum by (log_app, log_namespace) (rate(logd_messages_total{log_app="aap-soknad-api",log_level=~"Error"}[10m])) / sum by (log_app, log_namespace) (rate(logd_messages_total{log_app="aap-soknad-api"}[10m]))) > 15
      for: 5m
      action: "<https://logs.adeo.no/goto/33db4cfe9af54f191d99038b1e1e9d75|Check logs>"